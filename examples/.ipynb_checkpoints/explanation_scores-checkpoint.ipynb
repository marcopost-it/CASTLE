{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering and explanation of a classification model trained on the *Spambase* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('spambase.csv', header = None).to_numpy()\n",
    "labels = dataset[:,-1]\n",
    "dataset = dataset[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.914561196249592\n",
      "std_dev =  0.028419917503289226\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import sklearn.preprocessing \n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "scaled_dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=100, \n",
    "                                              max_depth=4,\n",
    "                                              random_state=0)\n",
    "scores = sklearn.model_selection.cross_val_score(clf, dataset, labels, cv=10,scoring='accuracy')\n",
    "\n",
    "print(\"accuracy =\", np.mean(scores))\n",
    "print(\"std_dev = \",np.std(scores))\n",
    "\n",
    "clf.fit(dataset,labels)\n",
    "model_labels = clf.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "\n",
    "# magagna per importare la cartella padre. \n",
    "# TODO: aggiustare con il setup giusto nel caso diventassimo famosi\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from clustering.ADP import ADP\n",
    "\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pivots found:  19\n"
     ]
    }
   ],
   "source": [
    "adp_clusterer = ADP(granularity = 0, distancetype = 'euclidean')\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "pipe = Pipeline([('scaling', scaler), ('clustering', adp_clusterer)])\n",
    "pipe.fit(dataset,model_labels.astype(int))\n",
    "\n",
    "print(\"Number of pivots found: \",  len(pipe['clustering'].pivots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainers.CASTLETabularExplainer import CASTLETabularExplainer \n",
    "\n",
    "#proximity_function = lambda x: 1/(1+x)\n",
    "#proximity_function = lambda x: np.exp(-x)\n",
    "#proximity_function = lambda x: -x\n",
    "#proximity_function = lambda x: 1 - (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "proximity_function = lambda x: np.max(x) - x\n",
    "\n",
    "explainer_castle = CASTLETabularExplainer(\n",
    "                                 dataset, \n",
    "                                 cluster_model = pipe, \n",
    "                                 pivots = pipe['clustering'].pivots,\n",
    "                                 class_names=['False','True'], \n",
    "                                 discretize_continuous=False,\n",
    "                                 sample_around_instance = True,\n",
    "                                 verbose=False,\n",
    "                                 proximity_function = proximity_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000 # Number of neighbors generated by the algorithm\n",
    "num_features = dataset.shape[1] # Number of features for LIME explanation\n",
    "num_clusters = len(pipe['clustering'].pivots) # Number of pivots to use for CASTLE explanation\n",
    "\n",
    "test_instance = dataset[0] # instance to explain\n",
    "\n",
    "exp_castle,exp_lime = explainer_castle.explain_instance(test_instance, clf.predict_proba, top_labels=1, \n",
    "                                               num_clusters = num_clusters, num_samples = num_samples, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation scores: comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME adjusted-R2:  0.601108568361618\n",
      "CASTLE adjusted-R2:  0.2211632387217971\n"
     ]
    }
   ],
   "source": [
    "castle_adjusted_r2 = 1 - (1-exp_castle.score)*(num_samples-1)/(num_samples-num_clusters-1)\n",
    "lime_adjusted_r2 = 1 - (1-exp_lime.score)*(num_samples-1)/(num_samples-num_features-1)\n",
    "\n",
    "print(\"LIME adjusted-R2: \", lime_adjusted_r2)\n",
    "print(\"CASTLE adjusted-R2: \", castle_adjusted_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
